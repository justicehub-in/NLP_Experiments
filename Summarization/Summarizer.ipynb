{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47891918",
   "metadata": {},
   "source": [
    "# Summarizer\n",
    "\n",
    "There are two styles of creating summaries viz. Extractive & Abstractive. Extractive summaries pick up important sentences as-is and put them in order for creating final summary. Abstractive summarization on the other hand paraphrases the important information to create crisp summary in its own words. **While abstractive summaries are more useful**, they are harder to create and evaluate. Hence, as first step we focus on extractive summarization which will pick up most important sentences and arrange them in the structure described above. Once this task is done correctly, then we can focus on the abstractive summarization.[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482346cb",
   "metadata": {},
   "source": [
    "# Table of Contents - Extractive Summarizer\n",
    "1. [Frequency Method](#freq)\n",
    "2. [OpenNyai's Extractive Summarizer for Indian Court Judgements](#opennyai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1f45b",
   "metadata": {},
   "source": [
    "## Extractive Summarizer\n",
    "### Frequency Method <a class=\"anchor\" id=\"freq\"></a>\n",
    "1. Find frequency of all words in the text data.\n",
    "2. Sentence Tokenize text data and assign value to each sentence based on presence of words.\n",
    "3. Sentences which contain more high frequency words will be kept in the summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011a2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74151636",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"my name is shubham kumar shukla. It is my pleasure to got opportunity to write article for xyz related to nlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f8ab03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d28d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35453cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqTable = {}\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in stopwords1:\n",
    "        continue\n",
    "    \n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b0ab82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 1,\n",
       " 'shubham': 1,\n",
       " 'kumar': 1,\n",
       " 'shukla': 1,\n",
       " '.': 1,\n",
       " 'pleasure': 1,\n",
       " 'got': 1,\n",
       " 'opportunity': 1,\n",
       " 'write': 1,\n",
       " 'article': 1,\n",
       " 'xyz': 1,\n",
       " 'related': 1,\n",
       " 'nlp': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqTable\n",
    "# Step-1 Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4fc85b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my name is shubham kumar shukla.',\n",
       " 'It is my pleasure to got opportunity to write article for xyz related to nlp']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e13066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my name is shubham kumar shukla.': 5,\n",
       " 'It is my pleasure to got opportunity to write article for xyz related to nlp': 8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceValue = {}\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq\n",
    "sentenceValue\n",
    "# Step 2 Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1643e0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]\n",
    "average = int(sumValues / len(sentenceValue))\n",
    "average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa26f325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is my pleasure to got opportunity to write article for xyz related to nlp'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    # A sentence is selected to be in the summary if its' value is more than 1.2*average\n",
    "    if (sentence in sentenceValue) and(sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += \"\" + sentence\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92697f25",
   "metadata": {},
   "source": [
    "Clearly this is not the best method. Important small statements would miss being part of the summary. There aer other AI ways as well to select sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eaabb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecf490c3",
   "metadata": {},
   "source": [
    "## OpenNyai's Extractive Summarizer for Indian Court Judgements <a class=\"anchor\" id=\"opennyai\"></a>\n",
    "\n",
    "Summary will have 5 sections **Facts summary, Arguments summary, Issue summary, Analysis Summary and Decision Summary.** Sectionwise summary will be created for each of it. The [rhetorical roles](https://github.com/d-saikrishna/NLP/blob/master/Summarization/Rhetorical%20Roles.ipynb) assigned to each sentence in judgement will help in this. But not all rhetorical roles are treated alike. “Issues” and “Decision” written in original judgement are very crisp and rich in information -- so these sentences are directly added to their section summaries without any evaluation. \"Preamble” is important in setting the context of case and also copied to main summary directly.[1]\n",
    "\n",
    "For remaining rhetorical roles, sentences are ranked in descending order of importance as predicted by the AI model and top-ranked sentences are added to their section sumamries summary. The AI model was trained on head-notes written for 10440 Supreme Court Judgements. More about this AI model is [here](https://github.com/Legal-NLP-EkStep/judgment_extractive_summarizer)[3]. In brief, the importance of a sentence is determined not alone by the words it has (as in frequency method or words based AI models) but also by the rhetorical roles of the sentence. \n",
    "\n",
    "**Thus, Summarizer model needs Rhetorical Role model output as input. Hence Rhetorical Role prediction model needs to run before Summarizer model runs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce302e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opennyai import Pipeline\n",
    "from opennyai.utils import Data\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65523538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Pre-processing will happen on CPU!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Sample court judgements\n",
    "text1 = open('SampleTexts/sample_judgment1.txt').read()\n",
    "text2 = open('SampleTexts/sample_judgment2.txt').read()\n",
    "\n",
    "# you can also load your text files directly into this\n",
    "texts_to_process = [text1, text2]\n",
    "\n",
    "# create Data object for data  preprocessing before running ML models\n",
    "data = Data(texts_to_process, preprocessing_nlp_model='en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e543e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have access to GPU then set this to True else False\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "823c28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Loading Rhetorical Role...\u001b[0m\n",
      "\u001b[38;5;4mℹ Rhetorical Roles will use CPU!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Loading Extractive summarizer...\u001b[0m\n",
      "\u001b[38;5;4mℹ Extractive Summarizer will use CPU!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/Extractive_summarization/model/model_headnotes/model.pt\" to /home/krishna/.opennyai/extractivesummarizer/model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421ffa38a2474b18bb9c2ec769f54ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/476M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 433/433 [00:00<00:00, 241957.58B/s]\n",
      "100%|██████████████████████████| 440473133/440473133 [31:33<00:00, 232668.53B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Preprocessing rhetorical role model input!!!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:16<00:00,  8.34s/it]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Processing documents with rhetorical role model!!!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:28<00:00, 14.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Processing documents with extractive summarizer model!!!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                 | 0/231508 [00:00<?, ?B/s]\u001b[A\n",
      "  0%|▏                                   | 1024/231508 [00:00<01:08, 3364.21B/s]\u001b[A\n",
      " 15%|█████                             | 34816/231508 [00:00<00:02, 79224.63B/s]\u001b[A\n",
      " 30%|██████████▏                       | 69632/231508 [00:00<00:01, 99161.45B/s]\u001b[A\n",
      " 60%|███████████████████▏            | 139264/231508 [00:01<00:00, 153322.79B/s]\u001b[A\n",
      "100%|████████████████████████████████| 231508/231508 [00:02<00:00, 102630.76B/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:17<00:00,  8.86s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(components=['Rhetorical_Role', 'Summarizer'], use_gpu=use_gpu, verbose=True,\n",
    "                    summarizer_summary_length=0.0)\n",
    "\n",
    "results = pipeline(data)\n",
    "\n",
    "json_result_doc_1 = results[0]\n",
    "summaries_doc_1 = results[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3ae7a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['PREAMBLE', 'facts', 'arguments', 'ANALYSIS', 'decision'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_doc_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0be1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The work was to be completed within one year that is before 15 th December 1972.\\nThe respondent thereafter filed a suit being O.S. No. 206 of 1989 before the Court of Civil Judge (Senior Division), Bhubaneswar (hereinafter referred to as the trial court) under Section 20 of the Arbitration Act, 1940 (for short, the 1940 Act) seeking reference of the dispute to arbitration.\\nBy order of the trial court dated 14th February 1990, the suit was decreed in favour of the respondent and he was directed to file the original F2 agreement in the court for referring the dispute to arbitration.\\nHowever, the respondent did not file the original F2 agreement as directed.\\nIn the meantime, the 1940 Act was repealed and the Arbitration and Conciliation Act, 1996 (for short, the 1996 Act) came into force.\\n4. The respondent thereafter filed an application in the disposed of suit before the trial court, praying for appointment of an arbitrator under the provisions of the 1996 Act.\\nThe respondent thereafter moved an application being MJC No. 36 of 2000 under Section 11 of the 1996 Act before the High Court for appointment of an arbitrator.\\nBeing aggrieved thereby, the appellants filed a petition being Arbitration Petition No. 153 of 2004 before the Court of District Judge, Cuttack under Section 34 of the 1996 Act for setting aside the award.\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_doc_1['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "554a2c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Point(s) for consideration:-\\n\\n5) The only point for consideration before this Court is whether in the present facts and circumstances of the case, the appellant has made out a case for grant of bail or not?\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_result_doc_2 = results[1]\n",
    "summaries_doc_2 = results[1]['summary']\n",
    "summaries_doc_2['issue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dc004",
   "metadata": {},
   "source": [
    "# References:\n",
    "1. https://opennyai.readthedocs.io/en/latest/summariser/summariser.html\n",
    "2. [Topcoder article on Frequency method](https://www.topcoder.com/thrive/articles/text-summarization-in-nlp)\n",
    "3. [Ek-Step Extractive Summarizer](https://github.com/Legal-NLP-EkStep/judgment_extractive_summarizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13cbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
